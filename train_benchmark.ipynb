{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Parameter\n",
    "from torch import Tensor\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.image as img\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import PIL\n",
    "import math\n",
    "import datetime\n",
    "import os\n",
    "from bpemb import BPEmb\n",
    "from torch import nn\n",
    "from image_caption_dataset import ImageCaptionDataset\n",
    "from multi_bpe import MultiBPE\n",
    "from multimodal_model import MMLSTM, BenchmarkLSTM\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "LOAD_PATH = './data/'\n",
    "seed = 420\n",
    "num_data = 200000\n",
    "maxlen = 32\n",
    "epochs = 15\n",
    "train_pct = 0.8\n",
    "bs=32\n",
    "lr = 1.0/math.sqrt(32/bs)\n",
    "is_multimodal=False\n",
    "train_visual_module=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(seed)\n",
    "# torch.cuda.manual_seed(seed)\n",
    "# torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU.\n",
    "np.random.seed(seed)  # Numpy module.\n",
    "random.seed(seed)  # Python random module.\n",
    "# torch.backends.cudnn.benchmark = False\n",
    "# torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(epoch, \n",
    "                    model, \n",
    "                    optimizer, \n",
    "                    scheduler,\n",
    "                    loss,\n",
    "                    FNAME):\n",
    "    \n",
    "    today = datetime.date.today()\n",
    "    PATH = f'./checkpoints/{today.strftime(\"checkpoint-%m-%d-%Y\")}/'\n",
    "    if not os.path.exists(PATH):\n",
    "        os.makedirs(PATH)\n",
    "    torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict() if scheduler !=None else None,\n",
    "            'loss': loss,\n",
    "            }, f'{PATH}{FNAME}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_latest_checkpoint(PATH, model, optimizer, scheduler):\n",
    "    checkpoint = torch.load(PATH)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    loss = checkpoint['loss']\n",
    "    scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "    return epoch, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _init_fn(worker_id):\n",
    "    np.random.seed(int(seed))\n",
    "    \n",
    "\n",
    "def get_dataset(tokenizer, path=LOAD_PATH, num_data = None, maxlen=64):\n",
    "    df = pd.read_csv(path + 'ml_stacked_data.csv')\n",
    "    if num_data != None:\n",
    "        text_df = df[:num_data]\n",
    "    else:\n",
    "        text_df = df\n",
    "    dataset = ImageCaptionDataset(text_df, tokenizer, maxlen=maxlen)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "def train(ml_model, \n",
    "          epochs, \n",
    "          train_data, \n",
    "          val_data, \n",
    "          loss_fct, \n",
    "          optimizer,\n",
    "          scheduler = None,\n",
    "          clip=2.0):\n",
    "    epoch_train_losses = []\n",
    "    epoch_val_losses = []\n",
    "        \n",
    "    for epoch in range(epochs):\n",
    "        ml_model.train()\n",
    "        epoch_train_loss, num_train_steps = 0, 0\n",
    "        for i, batch in enumerate(tqdm(train_data)):\n",
    "            text, img, target = batch['input_ids'].to(device), batch['image'].to(device), batch['label_ids'].to(device)\n",
    "            #print(img.size())\n",
    "            output = ml_model(text, img)\n",
    "            ml_model.zero_grad()\n",
    "            loss = torch.nn.functional.cross_entropy(output.view(-1, 320001), target.view(-1))\n",
    "            loss.backward()\n",
    "            \n",
    "            torch.nn.utils.clip_grad_norm_(ml_model.parameters(), clip)\n",
    "            optimizer.step()\n",
    "            if scheduler is not None:\n",
    "                scheduler.step()\n",
    "            epoch_train_loss += loss.item()\n",
    "            num_train_steps += 1\n",
    "            \n",
    "            if i % 2000 == 1:\n",
    "                print(\"Current train loss:\", epoch_train_loss/num_train_steps)\n",
    "\n",
    "        current_train_loss = epoch_train_loss/len(train_data)\n",
    "        epoch_train_losses.append(current_train_loss)\n",
    "        \n",
    "        ml_model.eval()\n",
    "        epoch_val_loss = 0\n",
    "        for i, batch in enumerate(tqdm(val_data)):\n",
    "            text, img, target = batch['input_ids'].to(device), batch['image'].to(device), batch['label_ids'].to(device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                output = ml_model(text, img)\n",
    "                loss = torch.nn.functional.cross_entropy(output.view(-1, output.size(-1)), target.view(-1))\n",
    "            epoch_val_loss += loss.item()\n",
    "            \n",
    "        current_val_loss = epoch_val_loss/len(val_data)\n",
    "        epoch_val_losses.append(current_val_loss)\n",
    "        perplexity = math.exp\n",
    "        print(\"=> Saving checkpoint...\")\n",
    "        if is_multimodal:\n",
    "            if train_visual_module:\n",
    "                FNAME = f'finetuned_visual_multimodal_lstm_{num_data}_{lr}_{epoch}-{current_val_loss:.2f}'\n",
    "                save_checkpoint(epoch, \n",
    "                                ml_model, \n",
    "                                optimizer, \n",
    "                                scheduler,\n",
    "                                current_val_loss,\n",
    "                                FNAME)\n",
    "            else:\n",
    "                FNAME = f'multimodal_lstm_{num_data}_{lr}_{epoch}-{current_val_loss:.2f}'\n",
    "                save_checkpoint(epoch, \n",
    "                                ml_model, \n",
    "                                optimizer, \n",
    "                                scheduler,\n",
    "                                current_val_loss,\n",
    "                                FNAME)\n",
    "\n",
    "        else:\n",
    "            FNAME = f'benchmark_model_{num_data}_{lr}_{epoch}-{current_val_loss:.2f}'\n",
    "            save_checkpoint(epoch, \n",
    "                            ml_model, \n",
    "                            optimizer, \n",
    "                            scheduler,\n",
    "                            current_val_loss,\n",
    "                            FNAME)\n",
    "        \n",
    "        print(f\"Epoch {epoch}:\\nTrain Loss: {current_train_loss}\\nVal loss: {current_val_loss}\")\n",
    "        \n",
    "    return epoch_train_losses, epoch_val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_benchmark(ml_model, \n",
    "                    epochs, \n",
    "                    train_data, \n",
    "                    val_data, \n",
    "                    loss_fct, \n",
    "                    optimizer,\n",
    "                    scheduler=None,\n",
    "                    clip=1.0):\n",
    "    epoch_train_losses = []\n",
    "    epoch_val_losses = []\n",
    "    perplexities = []\n",
    "    for epoch in range(epochs):\n",
    "        print(optimizer.param_groups[0][\"lr\"])\n",
    "        ml_model.train()\n",
    "        epoch_train_loss, num_train_steps = 0, 0\n",
    "        for i, batch in enumerate(tqdm(train_data)):\n",
    "            text, img, target = batch['input_ids'].to(device), batch['image'].to(device), batch['label_ids'].to(device)\n",
    "            output = ml_model(text)\n",
    "            ml_model.zero_grad()\n",
    "            loss = loss_fct(output.view(-1, 320001), target.view(-1))\n",
    "            loss.backward()\n",
    "            \n",
    "            torch.nn.utils.clip_grad_norm_(ml_model.parameters(), clip)\n",
    "            optimizer.step()\n",
    "            if scheduler is not None:\n",
    "                scheduler.step()\n",
    "            epoch_train_loss += loss.item()\n",
    "            num_train_steps += 1\n",
    "            \n",
    "            if i % 2000 == 1:\n",
    "                print(\"Current train loss:\", epoch_train_loss/num_train_steps)\n",
    "        current_train_loss = epoch_train_loss/len(train_data)\n",
    "        epoch_train_losses.append(current_train_loss)\n",
    "        \n",
    "        ml_model.eval()\n",
    "        epoch_val_loss = 0\n",
    "        for i, batch in enumerate(tqdm(val_data)):\n",
    "            text, img, target = batch['input_ids'].to(device), batch['image'].to(device), batch['label_ids'].to(device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                output = ml_model(text)\n",
    "                loss = loss_fct(output.view(-1, output.size(-1)), target.view(-1))\n",
    "               \n",
    "            epoch_val_loss += loss.item()\n",
    "            \n",
    "        current_val_loss = epoch_val_loss/len(val_data)\n",
    "        epoch_val_losses.append(current_val_loss)\n",
    "        perplexity = math.exp(current_val_loss)\n",
    "        \n",
    "        if len(perplexities) == 0:\n",
    "            perplexities.append(perplexity)\n",
    "        else:\n",
    "            if perplexity >= (3 * perplexities[-1]):\n",
    "                for g in torch.optim.param_groups:\n",
    "                    g['lr'] = g['lr']/2\n",
    "            perplexities.append(perplexity)\n",
    "            \n",
    "        print(f\"Epoch {epoch}:\\nTrain Loss: {current_train_loss}\\nVal loss: {current_val_loss}\")\n",
    "\n",
    "#         print(\"=> Saving checkpoint...\")\n",
    "#         if is_multimodal:\n",
    "#             if train_visual_module:\n",
    "#                 FNAME = f'finetuned_visual_multimodal_lstm_{num_data}_{lr}_{epoch}-{current_val_loss:.2f}'\n",
    "#                 save_checkpoint(epoch, \n",
    "#                                 ml_model, \n",
    "#                                 optimizer, \n",
    "#                                 scheduler,\n",
    "#                                 current_val_loss,\n",
    "#                                 FNAME)\n",
    "#             else:\n",
    "#                 FNAME = f'multimodal_lstm_{num_data}_{lr}_{epoch}-{current_val_loss:.2f}'\n",
    "#                 save_checkpoint(epoch, \n",
    "#                                 ml_model, \n",
    "#                                 optimizer, \n",
    "#                                 scheduler,\n",
    "#                                 current_val_loss,\n",
    "#                                 FNAME)\n",
    "\n",
    "#         else:\n",
    "#             FNAME = f'benchmark_model_{num_data}_{lr}_{epoch}-{current_val_loss:.2f}'\n",
    "#             save_checkpoint(epoch, \n",
    "#                             ml_model, \n",
    "#                             optimizer, \n",
    "#                             scheduler,\n",
    "#                             current_val_loss,\n",
    "#                             FNAME)\n",
    "    return epoch_train_losses, epoch_val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/5000 [00:00<21:59,  3.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current train loss: 12.646284580230713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2002/5000 [08:28<12:25,  4.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current train loss: 5.077624455198541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4002/5000 [16:46<04:08,  4.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current train loss: 4.480915155367873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [20:54<00:00,  3.99it/s]\n",
      "100%|██████████| 625/625 [02:04<00:00,  5.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:\n",
      "Train Loss: 4.3108990769863125\n",
      "Val loss: 3.4786369148254392\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/5000 [00:00<21:37,  3.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current train loss: 3.4299252033233643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2002/5000 [08:18<12:26,  4.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current train loss: 3.451037641171809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4002/5000 [16:35<04:07,  4.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current train loss: 3.3848061294093363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [20:43<00:00,  4.02it/s]\n",
      "100%|██████████| 625/625 [02:03<00:00,  5.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "Train Loss: 3.3553966972351073\n",
      "Val loss: 3.1218619747161864\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/5000 [00:00<21:20,  3.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current train loss: 3.474177360534668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2002/5000 [08:16<12:33,  3.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current train loss: 3.157481400521247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4002/5000 [16:33<04:08,  4.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current train loss: 3.1263588131933675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [20:41<00:00,  4.03it/s]\n",
      "100%|██████████| 625/625 [02:04<00:00,  5.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:\n",
      "Train Loss: 3.113920765209198\n",
      "Val loss: 2.979832181930542\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/5000 [00:00<21:48,  3.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current train loss: 3.0782840251922607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2002/5000 [08:16<12:30,  4.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current train loss: 3.0080290212259664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4002/5000 [16:33<04:07,  4.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current train loss: 2.9872314812599687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [20:41<00:00,  4.03it/s]\n",
      "100%|██████████| 625/625 [02:04<00:00,  5.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3:\n",
      "Train Loss: 2.9792554649829865\n",
      "Val loss: 2.889918435668945\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/5000 [00:00<21:31,  3.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current train loss: 3.002747416496277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2002/5000 [08:17<12:24,  4.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current train loss: 2.9031917698733456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4002/5000 [16:35<04:09,  4.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current train loss: 2.894876620997077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [20:44<00:00,  4.02it/s]\n",
      "100%|██████████| 625/625 [02:04<00:00,  5.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4:\n",
      "Train Loss: 2.8890707806110383\n",
      "Val loss: 2.805567984390259\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/5000 [00:00<21:59,  3.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current train loss: 2.9276753664016724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2002/5000 [08:18<12:31,  3.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current train loss: 2.828395057153273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4002/5000 [16:35<04:07,  4.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current train loss: 2.828215938875045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [20:44<00:00,  4.02it/s]\n",
      "100%|██████████| 625/625 [02:04<00:00,  5.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5:\n",
      "Train Loss: 2.821729228401184\n",
      "Val loss: 2.766284902191162\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/5000 [00:00<21:44,  3.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current train loss: 2.84767484664917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2002/5000 [08:18<12:23,  4.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current train loss: 2.775845371402584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4002/5000 [16:36<04:08,  4.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current train loss: 2.7721536929222537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [20:46<00:00,  4.01it/s]\n",
      "100%|██████████| 625/625 [02:06<00:00,  4.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6:\n",
      "Train Loss: 2.7696691148281096\n",
      "Val loss: 2.72775007019043\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/5000 [00:00<21:36,  3.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current train loss: 2.4008957147598267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2002/5000 [08:23<12:31,  3.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current train loss: 2.7305252931930206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4002/5000 [16:46<04:07,  4.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current train loss: 2.7282316796723634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [20:56<00:00,  3.98it/s]\n",
      "100%|██████████| 625/625 [02:06<00:00,  4.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7:\n",
      "Train Loss: 2.7262459456920625\n",
      "Val loss: 2.6945456871032714\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/5000 [00:00<22:40,  3.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current train loss: 2.8408461809158325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2002/5000 [08:25<12:34,  3.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current train loss: 2.6886003649794494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4002/5000 [16:49<04:10,  3.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current train loss: 2.6904490878735703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [21:02<00:00,  3.96it/s]\n",
      "100%|██████████| 625/625 [02:06<00:00,  4.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8:\n",
      "Train Loss: 2.6899516554832457\n",
      "Val loss: 2.669086597442627\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/5000 [00:00<22:23,  3.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current train loss: 2.571129322052002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2002/5000 [08:24<12:36,  3.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current train loss: 2.655496286821889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4002/5000 [16:47<04:10,  3.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current train loss: 2.6553199086887487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [21:03<00:00,  3.96it/s]\n",
      "100%|██████████| 625/625 [02:05<00:00,  4.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9:\n",
      "Train Loss: 2.6576039593219756\n",
      "Val loss: 2.655347897338867\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/5000 [00:00<21:50,  3.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current train loss: 2.5654048919677734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2002/5000 [08:18<12:14,  4.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current train loss: 2.627405057062993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4002/5000 [16:36<04:05,  4.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current train loss: 2.628507357665981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [20:45<00:00,  4.02it/s]\n",
      "100%|██████████| 625/625 [02:04<00:00,  5.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10:\n",
      "Train Loss: 2.6295034252643585\n",
      "Val loss: 2.634938250732422\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/5000 [00:00<21:37,  3.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current train loss: 2.6325340270996094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2002/5000 [08:18<12:32,  3.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current train loss: 2.603545538671724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4002/5000 [16:37<04:08,  4.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current train loss: 2.605269845934405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [20:45<00:00,  4.01it/s]\n",
      "100%|██████████| 625/625 [02:04<00:00,  5.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11:\n",
      "Train Loss: 2.6051934757709505\n",
      "Val loss: 2.61940299949646\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/5000 [00:00<21:22,  3.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current train loss: 2.7626837491989136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2002/5000 [08:22<12:21,  4.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current train loss: 2.579836149792095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4002/5000 [16:43<04:09,  4.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current train loss: 2.5822726332027277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [20:53<00:00,  3.99it/s]\n",
      "100%|██████████| 625/625 [02:05<00:00,  4.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12:\n",
      "Train Loss: 2.5822831481933592\n",
      "Val loss: 2.608886410522461\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/5000 [00:00<21:26,  3.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current train loss: 2.498419165611267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2002/5000 [08:19<12:32,  3.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current train loss: 2.562600621691236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4002/5000 [16:36<04:10,  3.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current train loss: 2.561991814253987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [20:45<00:00,  4.01it/s]\n",
      "100%|██████████| 625/625 [02:04<00:00,  5.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13:\n",
      "Train Loss: 2.561886626958847\n",
      "Val loss: 2.5930460548400878\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/5000 [00:00<21:45,  3.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current train loss: 2.4724626541137695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2002/5000 [08:20<12:15,  4.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current train loss: 2.538843631148934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4002/5000 [16:37<04:07,  4.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current train loss: 2.5422238860947677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [20:46<00:00,  4.01it/s]\n",
      "100%|██████████| 625/625 [02:04<00:00,  5.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14:\n",
      "Train Loss: 2.5432419083595277\n",
      "Val loss: 2.583121911621094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([4.3108990769863125,\n",
       "  3.3553966972351073,\n",
       "  3.113920765209198,\n",
       "  2.9792554649829865,\n",
       "  2.8890707806110383,\n",
       "  2.821729228401184,\n",
       "  2.7696691148281096,\n",
       "  2.7262459456920625,\n",
       "  2.6899516554832457,\n",
       "  2.6576039593219756,\n",
       "  2.6295034252643585,\n",
       "  2.6051934757709505,\n",
       "  2.5822831481933592,\n",
       "  2.561886626958847,\n",
       "  2.5432419083595277],\n",
       " [3.4786369148254392,\n",
       "  3.1218619747161864,\n",
       "  2.979832181930542,\n",
       "  2.889918435668945,\n",
       "  2.805567984390259,\n",
       "  2.766284902191162,\n",
       "  2.72775007019043,\n",
       "  2.6945456871032714,\n",
       "  2.669086597442627,\n",
       "  2.655347897338867,\n",
       "  2.634938250732422,\n",
       "  2.61940299949646,\n",
       "  2.608886410522461,\n",
       "  2.5930460548400878,\n",
       "  2.583121911621094])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_bpe = MultiBPE()\n",
    "all_data = get_dataset(tokenizer=multi_bpe, num_data=num_data,maxlen=maxlen)\n",
    "\n",
    "train_size = int(train_pct * len(all_data))\n",
    "test_size = len(all_data) - train_size\n",
    "train_dataset, val_test_dataset = torch.utils.data.random_split(all_data, [train_size, test_size])\n",
    "\n",
    "train_size = int(0.5 * len(val_test_dataset))\n",
    "test_size = len(val_test_dataset) - train_size\n",
    "val_dataset, test_dataset = torch.utils.data.random_split(val_test_dataset, [train_size, test_size])\n",
    "\n",
    "\n",
    "train_data = DataLoader(train_dataset, batch_size=bs, shuffle=True)\n",
    "val_data = DataLoader(val_dataset, batch_size=bs, shuffle=False)\n",
    "test_data = DataLoader(test_dataset, batch_size=bs, shuffle=False)\n",
    "\n",
    "benchmark_model = BenchmarkLSTM().to(device)\n",
    "# visual_multimodal_lstm = MMLSTM(is_multimodal=is_multimodal, \n",
    "#                                       train_visual_module=train_visual_module).to(device)\n",
    "\n",
    "optimizer = torch.optim.SGD(benchmark_model.parameters(), lr=lr)\n",
    "loss_fct = torch.nn.CrossEntropyLoss(ignore_index=320000, reduction='mean')\n",
    "\n",
    "# num_warmup_steps = (len(train_dataset) // bs)\n",
    "# num_training_steps = (len(train_dataset) // bs) * epochs\n",
    "# scheduler = transformers.get_linear_schedule_with_warmup(optimizer, \n",
    "#                                                          num_warmup_steps=num_warmup_steps, \n",
    "#                                                          num_training_steps=num_training_steps)\n",
    "# scheduler = transformers.get_constant_schedule_with_warmup(optimizer, \n",
    "#                                                          num_warmup_steps=num_warmup_steps) \n",
    "train_benchmark(benchmark_model, \n",
    "                epochs, \n",
    "                train_data, \n",
    "                val_data, \n",
    "                loss_fct, \n",
    "                optimizer,\n",
    "                scheduler=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([4.612036231708527, 3.849266048717499, 3.684289860057831, 3.5965754370212557],\n",
       " [3.955835499954224,\n",
       "  3.7210617919921876,\n",
       "  3.623933087158203,\n",
       "  3.5507487411499024])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "([4.612036231708527, 3.849266048717499, 3.684289860057831, 3.5965754370212557],\n",
    " [3.955835499954224,\n",
    "  3.7210617919921876,\n",
    "  3.623933087158203,\n",
    "  3.5507487411499024])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(ml_model, \n",
    "          epochs, \n",
    "          val_data, \n",
    "          loss_fct, \n",
    "          optimizer,\n",
    "          scheduler = None,\n",
    "          clip=2.0):\n",
    "    \n",
    "    ml_model.eval()\n",
    "    epoch_val_loss = 0\n",
    "    for i, batch in enumerate(tqdm(val_data)):\n",
    "        text, img, target = batch['input_ids'].to(device), batch['image'].to(device), batch['label_ids'].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = ml_model(text)\n",
    "            loss = loss_fct(output.view(-1, output.size(-1)), target.view(-1))\n",
    "\n",
    "        epoch_val_loss += loss.item()\n",
    "\n",
    "    current_val_loss = epoch_val_loss/len(val_data)\n",
    "    perplexity = math.exp(current_val_loss)\n",
    "\n",
    "\n",
    "    print(f\"Val loss: {current_val_loss}\")\n",
    "    print(f\"Val perp: {perplexity}\")\n",
    "\n",
    "    return current_val_loss, perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [02:04<00:00,  5.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 2.5833786556243896\n",
      "Val perp: 13.241802154368015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2.5833786556243896, 13.241802154368015)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(benchmark_model, \n",
    "    epochs, \n",
    "    test_data, \n",
    "    loss_fct, \n",
    "    optimizer,\n",
    "    scheduler=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_multimodal:\n",
    "    if train_visual_module:\n",
    "        torch.save(visual_multimodal_lstm.state_dict(), \n",
    "                   f'./saved_models/finetuned_visual_multimodal_lstm_{num_data}_{lr}_{epochs}v4')\n",
    "    else:\n",
    "        torch.save(train_visual_multimodal_lstm.state_dict(), \n",
    "                   f'./saved_models/multimodal_lstm_{num_data}_{lr}_{epochs}v4')\n",
    "else:\n",
    "    torch.save(benchmark_model.state_dict(), \n",
    "               f'./saved_models/benchmark_model_{num_data}_{lr}_{epochs}v7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "a =  [3.161041009902954,\n",
    "  2.813968430328369,\n",
    "  2.674389543533325,\n",
    "  2.5785831508636474,\n",
    "  2.514091403579712,\n",
    "  2.465382401275635,\n",
    "  2.4319754432678224,\n",
    "  2.3976976949691773,\n",
    "  2.38222297668457,\n",
    "  2.355729240036011,\n",
    "  2.331479719352722,\n",
    "  2.327339119338989,\n",
    "  2.323257204246521,\n",
    "  2.3015333766937256,\n",
    "  2.292942211151123]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.085536923187668"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "math.exp(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 23.595145929028277)\n",
      "(2, 16.67596448532435)\n",
      "(3, 14.50349338529962)\n",
      "(4, 13.178453045973917)\n",
      "(5, 12.355377625709929)\n",
      "(6, 11.76798138276216)\n",
      "(7, 11.38134308505272)\n",
      "(8, 10.997826858568226)\n",
      "(9, 10.828948627760905)\n",
      "(10, 10.54581648988851)\n",
      "(11, 10.293161259721039)\n",
      "(12, 10.250629510314461)\n",
      "(13, 10.208872593083909)\n",
      "(14, 9.989488365594339)\n",
      "(15, 9.90403461660927)\n"
     ]
    }
   ],
   "source": [
    "for i, num in enumerate(a):\n",
    "    print(f\"({i+1}, {math.exp(num)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
